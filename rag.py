import streamlit as st
import os
from dotenv import load_dotenv
import assemblyai as aai
import voyageai
from pymongo import MongoClient
from pymongo.operations import SearchIndexModel
import google.genai as genai
import tempfile
import uuid

load_dotenv()


@st.cache_resource
def init_services():
    api_key = os.getenv("ASSEMBLYAI_API_KEY")
    aai.settings.api_key = api_key

    vo = voyageai.Client(api_key=os.getenv("VOYAGE_API_KEY"))

    connection_string = os.getenv("MONGODB_CONNECTION_STRING")
    # å¢å¼· MongoDB é€£æ¥è¨­å®š
    client = MongoClient(connection_string)
    collection = client["rag_db"]["test"]

    llm = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

    return vo, collection, llm


def transcribe_audio(audio_file_path):
    config = aai.TranscriptionConfig(
        speech_model=aai.SpeechModel.best,
        language_code='zh',
        speaker_labels=True
    )

    transcript = aai.Transcriber(config=config).transcribe(audio_file_path)

    speaker_transcripts = []
    for utterance in transcript.utterances:
        speaker_transcripts.append({
            "speaker": f"Speaker {utterance.speaker}",
            "text": utterance.text
        })

    return speaker_transcripts


def create_embeddings_and_store(speaker_transcripts, vo, collection):

    speaker_sents = [f"{item['speaker']}: {item['text']}" for item in speaker_transcripts]

    embeds = vo.embed(
        texts=speaker_sents,
        model='voyage-2',
        input_type='document'
    ).embeddings

    docs = []
    session_id = str(uuid.uuid4())

    for (transcript, embed) in zip(speaker_sents, embeds):
        docs.append({
            "text": transcript,
            "embedding": embed,
            "session_id": session_id
        })

    # æ’å…¥æ–‡æª”åˆ° MongoDB
    try:
        result = collection.insert_many(docs)
        st.info(f"å·²æˆåŠŸæ’å…¥ {len(docs)} å€‹æ–‡æª”")
    except Exception as e:
        st.error(f"æ’å…¥æ–‡æª”æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        raise

    # å‰µå»ºå‘é‡ç´¢å¼•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    try:
        search_index_model = SearchIndexModel(
            definition={
                "fields": [
                    {
                        "type": "vector",
                        "numDimensions": 1024,
                        "path": "embedding",
                        "similarity": "cosine"
                    }
                ]
            },
            name="vector_index",
            type="vectorSearch"
        )
        
        existing_indexes = list(collection.list_search_indexes())
        vector_index_exists = any(idx.get('name') == 'vector_index' for idx in existing_indexes)
        
        if not vector_index_exists:
            collection.create_search_index(model=search_index_model)
            st.info("å·²å‰µå»ºå‘é‡ç´¢å¼•")
        else:
            st.info("å‘é‡ç´¢å¼•å·²å­˜åœ¨")
            
    except Exception as e:
        st.warning(f"ç´¢å¼•æ“ä½œæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        st.info("æ•¸æ“šå·²æˆåŠŸå„²å­˜ï¼Œç´¢å¼•å¯èƒ½éœ€è¦ç¨å¾Œå‰µå»º")

    return session_id, len(docs)


def search_and_generate_response(query, vo, collection, llm, session_id=None):
    query_embed = vo.embed(
        [query],
        model='voyage-2',
        input_type='query'
    ).embeddings[0]

    search_pipeline = [
        {
            "$vectorSearch": {
                "index": "vector_index",
                "queryVector": query_embed,
                "path": "embedding",
                "limit": 5,
                "exact": True
            }
        },
        {
            "$project": {
                "_id": 0,
                "text": 1,
                "session_id": 1,
                "score": {"$meta": "vectorSearchScore"}
            }
        }
    ]

    if session_id:
        search_pipeline.insert(1, {
            "$match": {"session_id": session_id}
        })

    try:
        results = list(collection.aggregate(search_pipeline))
    except Exception as e:
        error_msg = str(e)
        return f"æœç´¢æ™‚ç™¼ç”ŸéŒ¯èª¤: {error_msg}", []

    if not results:
        return "æŠ±æ­‰ï¼Œæˆ‘åœ¨è³‡æ–™åº«ä¸­æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šã€‚", []

    merged_context = "\n\n---\n\n".join([item['text'] for item in results])

    prompt = (
        f"Context information is below.\n"
        f"----------------------- \n"
        f"{merged_context}\n"
        f"----------------------- \n"
        f"Given the context information above, think step by step "
        f"to answer the query in a crisp manner. Please answer in Traditional Chinese.\n"
        f"Query: {query}\n"
        f"Answer: "
    )

    try:
        response = llm.models.generate_content(
            model='gemini-2.0-flash-exp',
            contents=prompt
        )
        answer = response.candidates[0].content.parts[0].text
    except Exception as e:
        answer = f"ç”Ÿæˆå›ç­”æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"

    return answer, results


def main():
    st.set_page_config(
        page_title="RAG-èªéŸ³å…§å®¹æª¢ç´¢",
        page_icon="ğŸµ",
        layout="wide"
    )

    st.title("RAG-èªéŸ³å…§å®¹æª¢ç´¢")
    st.markdown("ä¸Šå‚³éŸ³è¨Šæª”æ¡ˆï¼Œè®“AIå¹«æ‚¨åˆ†æå’Œå›ç­”å•é¡Œ")

    try:
        vo, collection, llm = init_services()
        st.success("æ‰€æœ‰æœå‹™å·²æˆåŠŸé€£æ¥")
    except Exception as e:
        st.error(f"æœå‹™åˆå§‹åŒ–å¤±æ•—: {str(e)}")
        st.info("è«‹æª¢æŸ¥æ‚¨çš„ç’°å¢ƒè®Šæ•¸è¨­å®š (ASSEMBLYAI_API_KEY, VOYAGE_API_KEY, MONGODB_CONNECTION_STRING, GEMINI_API_KEY)")
        return

    with st.sidebar:
        st.header("éŸ³è¨Šæª”æ¡ˆä¸Šå‚³")
        
        # æ·»åŠ æ‰‹å‹•æ¸…ç†æŒ‰éˆ•
        if st.button("ä¸€éµæ¸…é™¤è³‡æ–™åº«", help="æ¸…ç©ºæ‰€æœ‰è³‡æ–™ä¸¦é‡å»ºæ­£ç¢ºçš„å‘é‡ç´¢å¼•"):
            try:
                with st.spinner("æ­£åœ¨æ¸…ç†è³‡æ–™åº«..."):
                    # æ¸…ç©ºè³‡æ–™
                    collection.delete_many({})
                    
                    # åˆªé™¤èˆŠç´¢å¼•
                    try:
                        collection.drop_search_index("vector_index")
                        st.info("å·²åˆªé™¤èˆŠç´¢å¼•")
                    except Exception as e:
                        st.info("ç´¢å¼•ä¸å­˜åœ¨æˆ–å·²è¢«åˆªé™¤")
                    
                    # ç­‰å¾…ä¸€æ®µæ™‚é–“è®“ç´¢å¼•å®Œå…¨åˆªé™¤
                    import time
                    time.sleep(2)
                    
                    st.success("è³‡æ–™åº«å·²æ¸…ç†å®Œæˆï¼Œè«‹é‡æ–°ä¸Šå‚³éŸ³è¨Šæª”æ¡ˆ")
                    
                    # æ¸…é™¤ session state
                    if 'session_id' in st.session_state:
                        del st.session_state.session_id
                    if 'transcripts' in st.session_state:
                        del st.session_state.transcripts
                    if 'chat_history' in st.session_state:
                        del st.session_state.chat_history
                        
            except Exception as e:
                st.error(f"æ¸…ç†è³‡æ–™åº«æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

        uploaded_file = st.file_uploader(
            "é¸æ“‡éŸ³è¨Šæª”æ¡ˆ",
            type=['mp3', 'wav', 'm4a', 'flac', 'ogg'],
            help="æ”¯æ´æ ¼å¼: MP3, WAV, M4A, FLAC, OGG"
        )

        if uploaded_file is not None:
            st.audio(uploaded_file, format='audio/wav')
            
            if st.button("é–‹å§‹è™•ç†éŸ³è¨Š", type="primary"):
                # å‰µå»ºè‡¨æ™‚æª”æ¡ˆ
                with tempfile.NamedTemporaryFile(delete=False,
                                                 suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_file_path = tmp_file.name

                try:
                    # æ­¥é©Ÿ1: è½‰éŒ„éŸ³è¨Š
                    with st.spinner("æ­£åœ¨è½‰éŒ„éŸ³è¨Š..."):
                        speaker_transcripts = transcribe_audio(tmp_file_path)
                        st.session_state.transcripts = speaker_transcripts
                    
                    st.success("éŸ³è¨Šè½‰éŒ„å®Œæˆ")
                    
                    # æ­¥é©Ÿ2: ç”Ÿæˆå‘é‡åµŒå…¥ä¸¦å„²å­˜
                    with st.spinner("æ­£åœ¨ç”ŸæˆåµŒå…¥å‘é‡ä¸¦å„²å­˜åˆ°è³‡æ–™åº«..."):
                        session_id, doc_count = create_embeddings_and_store(
                            speaker_transcripts, vo, collection
                        )
                        st.session_state.session_id = session_id
                    
                    st.success(f"å·²æˆåŠŸè™•ç†ä¸¦å„²å­˜ {doc_count} å€‹æ–‡æª”ç‰‡æ®µ")

                except Exception as e:
                    st.error(f"è™•ç†éŸ³è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

                finally:
                    os.unlink(tmp_file_path)

        if 'transcripts' in st.session_state:
            st.header("è½‰éŒ„çµæœ")
            with st.expander("æŸ¥çœ‹å®Œæ•´è½‰éŒ„", expanded=False):
                for i, item in enumerate(st.session_state.transcripts):
                    st.markdown(f"**{item['speaker']}:** {item['text']}")

    st.header("AI åŠ©æ‰‹")

    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []

    chat_container = st.container()
    with chat_container:
        for message in st.session_state.chat_history:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    if query := st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ..."):
        if 'session_id' not in st.session_state:
            st.warning("è«‹å…ˆä¸Šå‚³ä¸¦è™•ç†éŸ³è¨Šæª”æ¡ˆ")
            return

        st.session_state.chat_history.append({"role": "user", "content": query})

        with st.chat_message("user"):
            st.markdown(query)

        with st.chat_message("assistant"):
            with st.spinner("æ­£åœ¨æ€è€ƒä¸­..."):
                try:
                    answer, search_results = search_and_generate_response(
                        query, vo, collection, llm, st.session_state.session_id
                    )

                    st.markdown(answer)

                    if search_results:
                        with st.expander("ğŸ“š ç›¸é—œè³‡è¨Šä¾†æº", expanded=False):
                            for i, result in enumerate(search_results):
                                score = result.get('score', 'N/A')
                                st.markdown(f"**ä¾†æº {i + 1}** (ç›¸ä¼¼åº¦: {score:.3f}):")
                                st.markdown(f"```\n{result['text']}\n```")

                    st.session_state.chat_history.append({"role": "assistant", "content": answer})

                except Exception as e:
                    error_msg = f"ç”Ÿæˆå›ç­”æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
                    st.error(error_msg)
                    st.session_state.chat_history.append({"role": "assistant", "content": error_msg})

    if st.session_state.chat_history:
        if st.button("æ¸…é™¤èŠå¤©è¨˜éŒ„"):
            st.session_state.chat_history = []
            st.rerun()


if __name__ == "__main__":
    main()
